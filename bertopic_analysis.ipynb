{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "from helpers import convert_filename\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "from wordcloud import WordCloud\n",
    "from bertopic import BERTopic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RESULTS_DIR = \"findings\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = None\n",
    "with open(\"stopwords.txt\", \"r\") as stop_file:\n",
    "    stop_words = set(stop_file.read().splitlines())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Start Lemmatized Tweets Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets = []\n",
    "classes = []\n",
    "candidates = []\n",
    "lemm_tweets = None\n",
    "\n",
    "with open(\"data/lemm_tweets.json\", \"r\") as in_file:\n",
    "    lemm_tweets = json.load(in_file)\n",
    "\n",
    "for candidate, candidate_tweets in lemm_tweets.items():\n",
    "    candidates.append(candidate)\n",
    "    for tweet in candidate_tweets:\n",
    "        non_stop_words = []\n",
    "\n",
    "        for word in tweet.split():\n",
    "            if word not in stop_words:\n",
    "                non_stop_words.append(word)\n",
    "\n",
    "        if len(non_stop_words) > 0:\n",
    "            tweets.append(\" \".join(non_stop_words))\n",
    "            classes.append(candidate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "title_font = {\"family\": \"Times\", \"size\": 16}\n",
    "\n",
    "for cand, cand_tweets in lemm_tweets.items():\n",
    "    wc = WordCloud(max_words=100, random_state=42, width=800, height=600,\n",
    "                   stopwords=stop_words, background_color=\"white\", colormap=\"tab10\", min_font_size=6)\n",
    "    wc.generate(\" \".join(cand_tweets))\n",
    "\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    plt.title(cand, fontdict=title_font, pad=20)\n",
    "    plt.imshow(wc, interpolation=\"bilinear\")\n",
    "    plt.axis(\"off\")\n",
    "\n",
    "    file_name = convert_filename(cand).lower()\n",
    "    wc_svg = wc.to_svg(embed_font=True)\n",
    "    with open(f\"{RESULTS_DIR}/wc_{file_name}.svg\", \"w\") as out_file:\n",
    "        out_file.write(wc_svg)\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_model = BERTopic(language=\"multilingual\", verbose=True)\n",
    "topics, probs = topic_model.fit_transform(tweets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_model.reduce_topics(tweets, nr_topics=24)\n",
    "\n",
    "topic_labels_lemm = topic_model.generate_topic_labels(\n",
    "    nr_words=5, topic_prefix=False, separator=\", \")\n",
    "\n",
    "topic_model.set_topic_labels(topic_labels_lemm)\n",
    "df = topic_model.get_topic_info()\n",
    "df.to_excel(f\"{RESULTS_DIR}/topics.xlsx\", index=False)\n",
    "df.head(25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = topic_model.visualize_barchart(top_n_topics=12, n_words=8, width=300)\n",
    "fig.write_image(f\"{RESULTS_DIR}/topic_word_scores.pdf\")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "topics_per_class = topic_model.topics_per_class(tweets, classes=classes)\n",
    "fig = topic_model.visualize_topics_per_class(\n",
    "    topics_per_class, top_n_topics=12, width=1000, custom_labels=True)\n",
    "fig.write_html(f\"{RESULTS_DIR}/topics_per_class.html\")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for candidate in candidates:\n",
    "    df = topics_per_class.query('Class == \"' + candidate + '\" and Topic > -1').sort_values(\n",
    "        by=[\"Frequency\"], ascending=False).loc[:, \"Words\":\"Name\"].drop(\"Class\", axis=1).head(12)\n",
    "\n",
    "    file_name = convert_filename(candidate).lower()\n",
    "    df.to_excel(f\"{RESULTS_DIR}/{file_name}.xlsx\", index=False)\n",
    "\n",
    "    print(candidate)\n",
    "    print(df.to_string(index=False))\n",
    "    print(\"\\n\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "topic_model.visualize_documents(\n",
    "    tweets, height=600, custom_labels=True, topics=list(range(12)))\n",
    "\"\"\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tfnew",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
